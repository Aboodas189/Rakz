{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import streamlit as st\n",
    "from streamlit_webrtc import WebRtcMode, webrtc_streamer\n",
    "import av\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns  # Import seaborn for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTS = cv.FONT_HERSHEY_SIMPLEX\n",
    "CENTER_THRESHOLD = 5\n",
    "SIDE_THRESHOLD   = 2\n",
    "BLINK_THRESHOLD  = 5\n",
    "DISCOUNT_CENTER  = 1\n",
    "DISCOUNT_SIDE    = 1\n",
    "DISCOUNT_EYES    = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE   = [362, 382, 381, 380, 374, 373, 390, 249,263, 466, 388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE  = [33, 7, 163, 144, 145, 153, 154, 155,133, 173, 157, 158, 159, 160, 161, 246]\n",
    "LEFT_IRIS  = [474, 475, 476, 477]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global variables for tracking\n",
    "focus_score = 100\n",
    "last_look_centered_time = None\n",
    "not_looking_start_time = None\n",
    "blink_start_time = None\n",
    "total_blinks = 0\n",
    "blink_detected = False\n",
    "eyes_closed_start_time = None\n",
    "# Add variables to track the last time we increased or decreased the focus score\n",
    "last_focus_increase_time = None\n",
    "last_focus_decrease_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used this function to calculates the straight-line distance (Euclidean distance) between two points, point1 and point2, in a 2D space. with formla sqrt{(X2 - X1)^2 + (Y2 - Y1)^2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "  return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![شرح الصورة](Euclidean-distance.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aslo here we used this function to check the eyes are blinking by comparing the width (horizontal distance) and height (vertical distance) of both eyes.\n",
    "\n",
    "so we calculates the ratio of horizontal distance to vertical distance for each eye. If this ratio is too high, the eye it might be blinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blink_ratio(landmarks, right_indices, left_indices):\n",
    "  rh_distance = euclidean_distance(landmarks[right_indices[0]] , landmarks[right_indices[8]])\n",
    "  rv_distance = euclidean_distance(landmarks[right_indices[12]], landmarks[right_indices[4]])\n",
    "  lh_distance = euclidean_distance(landmarks[left_indices[0]]  , landmarks[left_indices[8]])\n",
    "  lv_distance = euclidean_distance(landmarks[left_indices[12]] , landmarks[left_indices[4]])\n",
    "\n",
    "  if rv_distance == 0 or lv_distance == 0:\n",
    "      return float('inf')\n",
    "\n",
    "  re_ratio = rh_distance / rv_distance\n",
    "  le_ratio = lh_distance / lv_distance\n",
    "  return (re_ratio + le_ratio) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![شرح الصورة](points_eyes.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now this function converts facial landmarks (detected face points) into pixel that correspond to positions on the real image.\n",
    "\n",
    "we have to multip the normalized landmark positions by the image's width and height to get actual pixel positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_detection(img, results):\n",
    "  img_height, img_width = img.shape[:2]\n",
    "  return [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now this functio it gave where the eyes are looking ? (left, right, center) by on the position of the iris.\n",
    "\n",
    "by compares the iris position within the limit of the eye (left to right).\n",
    "\n",
    "If the ratio indicates a blink, it returns \"Blink.\" Otherwise, it checks if the iris is closer to the left or right side of the eye and returns \"Left\" or \"Right.\" If it’s centered, it returns \"Center.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_direction(eye_points, iris_center, ratio):\n",
    "  eye_left = np.min(eye_points[:, 0])\n",
    "  eye_right = np.max(eye_points[:, 0])\n",
    "\n",
    "  hor_range = eye_right - eye_left\n",
    "  iris_x, _ = iris_center\n",
    "\n",
    "  if ratio > 5.5:\n",
    "      return \"Blink\"\n",
    "  elif iris_x < eye_left + hor_range * 0.3:\n",
    "      return \"Left\"\n",
    "  elif iris_x > eye_right - hor_range * 0.3:\n",
    "      return \"Right\"\n",
    "  else:\n",
    "      return \"Center\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Core function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, face_mesh, focus_score, last_look_centered_time, not_looking_start_time, blink_start_time, blink_detected, eyes_closed_start_time, last_focus_increase_time, last_focus_decrease_time):\n",
    "  frame = cv.flip(frame, 1)\n",
    "  rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "  results = face_mesh.process(rgb_frame)\n",
    "\n",
    "  eye_direction_text = \"Unknown\"\n",
    "  face_position = \"Unknown\"\n",
    "\n",
    "  current_time = time.time()  # Moved here to ensure it's available for all branches\n",
    "\n",
    "  if results.multi_face_landmarks:\n",
    "      mesh_points = landmarks_detection(frame, results)\n",
    "      \n",
    "      # Face position monitoring\n",
    "      face_3d = []\n",
    "      face_2d = []\n",
    "      for idx, lm in enumerate(results.multi_face_landmarks[0].landmark):\n",
    "          if idx in [1, 33, 61, 199, 263, 291]:\n",
    "              x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "              face_2d.append([x, y])\n",
    "              face_3d.append([x, y, lm.z])\n",
    "      \n",
    "      face_2d = np.array(face_2d, dtype=np.float64)\n",
    "      face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "      focal_length = 1 * frame.shape[1]\n",
    "      cam_matrix = np.array([[focal_length, 0, frame.shape[1] / 2],\n",
    "                             [0, focal_length, frame.shape[0] / 2],\n",
    "                             [0, 0, 1]])\n",
    "      dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "      success, rot_vec, trans_vec = cv.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "      rmat, jac = cv.Rodrigues(rot_vec)\n",
    "      angles, mtxR, mtxQ, Qx, Qy, Qz = cv.RQDecomp3x3(rmat)\n",
    "\n",
    "      x = angles[0] * 360\n",
    "      y = angles[1] * 360\n",
    "\n",
    "      if y < -10:\n",
    "          face_position = \"Looking Left\"\n",
    "      elif y > 10:\n",
    "          face_position = \"Looking Right\"\n",
    "      elif x < -10:\n",
    "          face_position = \"Looking Down\"\n",
    "      elif x > 10:\n",
    "          face_position = \"Looking Up\"\n",
    "      else:\n",
    "          face_position = \"Forward\"\n",
    "\n",
    "      # Eye direction and blink detection\n",
    "      ratio = blink_ratio(mesh_points, RIGHT_EYE, LEFT_EYE)\n",
    "      left_iris_points = np.array([mesh_points[i] for i in LEFT_IRIS], dtype=np.int32)\n",
    "      right_iris_points = np.array([mesh_points[i] for i in RIGHT_IRIS], dtype=np.int32)\n",
    "      (l_cx, l_cy), l_radius = cv.minEnclosingCircle(left_iris_points)\n",
    "      (r_cx, r_cy), r_radius = cv.minEnclosingCircle(right_iris_points)\n",
    "      center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    "      center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "      left_eye_direction = eye_direction(np.array([mesh_points[p] for p in LEFT_EYE]), center_left, ratio)\n",
    "      right_eye_direction = eye_direction(np.array([mesh_points[p] for p in RIGHT_EYE]), center_right, ratio)\n",
    "\n",
    "      if left_eye_direction == right_eye_direction:\n",
    "          eye_direction_text = left_eye_direction\n",
    "      else:\n",
    "          eye_direction_text = left_eye_direction if left_eye_direction in [\"Left\", \"Right\"] else right_eye_direction\n",
    "\n",
    "      # Focus scoring algorithm\n",
    "      if face_position == \"Forward\" and eye_direction_text == \"Center\":\n",
    "          if last_look_centered_time is None:\n",
    "              last_look_centered_time = current_time\n",
    "          not_looking_start_time = None\n",
    "          if current_time - last_look_centered_time >= CENTER_THRESHOLD:\n",
    "              # Increase focus score by 1% every 1 second when increasing\n",
    "              if last_focus_increase_time is None or current_time - last_focus_increase_time >= 1:\n",
    "                  focus_score = min(100, focus_score + 1)\n",
    "                  last_focus_increase_time = current_time\n",
    "      else:\n",
    "          last_look_centered_time = None\n",
    "          if not not_looking_start_time:\n",
    "              not_looking_start_time = current_time\n",
    "          elif current_time - not_looking_start_time >= SIDE_THRESHOLD:\n",
    "              # Decrease focus score by 1% every 1 second when decreasing\n",
    "              if last_focus_decrease_time is None or current_time - last_focus_decrease_time >= 1:\n",
    "                  focus_score = max(0, focus_score - 1)\n",
    "                  last_focus_decrease_time = current_time\n",
    "\n",
    "      if ratio > 5.5:\n",
    "          if not blink_detected:\n",
    "              blink_start_time = current_time\n",
    "              blink_detected = True\n",
    "      else:\n",
    "          if blink_detected:\n",
    "              blink_detected = False\n",
    "\n",
    "      # Display information on frame\n",
    "      cv.putText(frame, f\"Face: {face_position}\", (50, 50), FONTS, 1, (255, 0, 0), 2, cv.LINE_AA)\n",
    "      cv.putText(frame, f\"Eyes: {eye_direction_text}\", (50, 100), FONTS, 1, (0, 255, 0), 2, cv.LINE_AA)\n",
    "      cv.putText(frame, f\"Focus Score: {focus_score}%\", (50, 150), FONTS, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "  else:\n",
    "      # If no face is detected, decrease focus score by 1% every 1 second\n",
    "      if last_focus_decrease_time is None or current_time - last_focus_decrease_time >= 1:\n",
    "          focus_score = max(0, focus_score - 1)\n",
    "          last_focus_decrease_time = current_time\n",
    "\n",
    "  return (frame, focus_score, last_look_centered_time, not_looking_start_time, blink_start_time, blink_detected, eye_direction_text, face_position, last_focus_increase_time, last_focus_decrease_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:\n",
    "  img = frame.to_ndarray(format=\"bgr24\")\n",
    "  global focus_score, last_look_centered_time, not_looking_start_time, blink_start_time, blink_detected, eyes_closed_start_time\n",
    "  global last_focus_increase_time, last_focus_decrease_time  # Include new global variables\n",
    "  global CENTER_THRESHOLD, SIDE_THRESHOLD, BLINK_THRESHOLD, DISCOUNT_SIDE, DISCOUNT_EYES\n",
    "\n",
    "  with mp_face_mesh.FaceMesh(\n",
    "      max_num_faces=1,\n",
    "      refine_landmarks=True,\n",
    "      min_detection_confidence=0.7,\n",
    "      min_tracking_confidence=0.7,\n",
    "  ) as face_mesh:\n",
    "      (img, focus_score, last_look_centered_time, not_looking_start_time, \n",
    "       blink_start_time, blink_detected, _, _, last_focus_increase_time, last_focus_decrease_time) = process_frame(\n",
    "          img, face_mesh, focus_score, last_look_centered_time, not_looking_start_time, \n",
    "          blink_start_time, blink_detected, eyes_closed_start_time, last_focus_increase_time, last_focus_decrease_time\n",
    "      )\n",
    "\n",
    "  return av.VideoFrame.from_ndarray(img, format=\"bgr24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_uploaded_video(video_file):\n",
    "  tfile = tempfile.NamedTemporaryFile(delete=False) \n",
    "  tfile.write(video_file.read())\n",
    "  \n",
    "  cap = cv.VideoCapture(tfile.name)\n",
    "  \n",
    "  global focus_score, last_look_centered_time, not_looking_start_time, blink_start_time, blink_detected, eyes_closed_start_time\n",
    "  # Initialize the new variables\n",
    "  last_focus_increase_time = None\n",
    "  last_focus_decrease_time = None\n",
    "\n",
    "  focus_score = 100\n",
    "  last_look_centered_time = None\n",
    "  not_looking_start_time = None\n",
    "  blink_start_time = None\n",
    "  blink_detected = False\n",
    "  eyes_closed_start_time = None\n",
    "  \n",
    "  data = []\n",
    "  sleep_count = 0\n",
    "  sleep_start = None\n",
    "  total_blinks = 0\n",
    "  start_time = None\n",
    "  \n",
    "  with mp_face_mesh.FaceMesh(\n",
    "      max_num_faces=1,\n",
    "      refine_landmarks=True,\n",
    "      min_detection_confidence=0.7,\n",
    "      min_tracking_confidence=0.7,\n",
    "  ) as face_mesh:\n",
    "      while cap.isOpened():\n",
    "          ret, frame = cap.read()\n",
    "          if not ret:\n",
    "              break\n",
    "          \n",
    "          (frame, focus_score, last_look_centered_time, not_looking_start_time, \n",
    "           blink_start_time, blink_detected, eye_direction, face_position, last_focus_increase_time, last_focus_decrease_time) = process_frame(\n",
    "              frame, face_mesh, focus_score, last_look_centered_time, not_looking_start_time, \n",
    "              blink_start_time, blink_detected, eyes_closed_start_time, last_focus_increase_time, last_focus_decrease_time\n",
    "          )\n",
    "          \n",
    "          timestamp = cap.get(cv.CAP_PROP_POS_MSEC) / 1000  # Convert to seconds\n",
    "          \n",
    "          if start_time is None:\n",
    "              start_time = timestamp\n",
    "\n",
    "          # Remove unknown data\n",
    "          if eye_direction == \"Unknown\" or face_position == \"Unknown\":\n",
    "              continue\n",
    "\n",
    "          # Count total blinks\n",
    "          if blink_detected:\n",
    "              total_blinks += 1\n",
    "          \n",
    "          # Count continuous 10-second sleep intervals\n",
    "          if eye_direction == \"Blink\" and face_position != \"Forward\":\n",
    "              if sleep_start is None:\n",
    "                  sleep_start = timestamp\n",
    "              elif timestamp - sleep_start >= 10:\n",
    "                  sleep_count += 1\n",
    "                  sleep_start = None\n",
    "          else:\n",
    "              sleep_start = None\n",
    "          \n",
    "          data.append({\n",
    "              'timestamp': timestamp,\n",
    "              'focus_score': focus_score,\n",
    "              'eye_direction': eye_direction,\n",
    "              'face_position': face_position,\n",
    "              'is_front_camera': face_position == \"Forward\" and eye_direction == \"Center\"\n",
    "          })\n",
    "  \n",
    "  cap.release()\n",
    "  df = pd.DataFrame(data)\n",
    "  df['sleep_count'] = sleep_count\n",
    "  df['total_blinks'] = total_blinks\n",
    "  df['timestamp_min'] = (df['timestamp'] - start_time) / 60  # Convert to minutes\n",
    "\n",
    "  # =========================\n",
    "  # Updated Code Starts Here\n",
    "  # =========================\n",
    "  # Calculate Front Camera and Not Front Camera Time with the specified logic\n",
    "  total_front_seconds = 0\n",
    "  total_not_front_seconds = 0\n",
    "  min_continuous_seconds = 60  # 1 minute\n",
    "\n",
    "  current_state = None\n",
    "  state_start_time = None\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "      state = 'front' if row['is_front_camera'] else 'not_front'\n",
    "      if current_state is None:\n",
    "          current_state = state\n",
    "          state_start_time = row['timestamp']\n",
    "      elif state != current_state:\n",
    "          duration = row['timestamp'] - state_start_time\n",
    "          if current_state == 'front':\n",
    "              # Always add time for 'front' state\n",
    "              total_front_seconds += duration\n",
    "          else:\n",
    "              # Only add time for 'not_front' state if duration exceeds 1 minute\n",
    "              if duration >= min_continuous_seconds:\n",
    "                  total_not_front_seconds += duration\n",
    "          current_state = state\n",
    "          state_start_time = row['timestamp']\n",
    "      # If the state hasn't changed, we continue accumulating time in the current state\n",
    "\n",
    "  # After iterating, handle the last accumulated state\n",
    "  if current_state is not None:\n",
    "      duration = df['timestamp'].iloc[-1] - state_start_time\n",
    "      if current_state == 'front':\n",
    "          total_front_seconds += duration\n",
    "      else:\n",
    "          if duration >= min_continuous_seconds:\n",
    "              total_not_front_seconds += duration\n",
    "\n",
    "  total_front_minutes = total_front_seconds / 60\n",
    "  total_not_front_minutes = total_not_front_seconds / 60\n",
    "\n",
    "  # Add these totals to the dataframe as metadata\n",
    "  df.attrs['total_front_minutes'] = total_front_minutes\n",
    "  df.attrs['total_not_front_minutes'] = total_not_front_minutes\n",
    "\n",
    "  # =========================\n",
    "  # Updated Code Ends Here\n",
    "  # =========================\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dashboard(df):\n",
    "  st.subheader(\"Individual Analytics\")\n",
    "  \n",
    "  # Focus Score Trend\n",
    "  fig_focus = go.Figure()\n",
    "  fig_focus.add_trace(go.Scatter(x=df['timestamp_min'], y=df['focus_score'], mode='lines', name='Focus Score'))\n",
    "  fig_focus.update_layout(title='Focus Score Over Time', xaxis_title='Time (minutes)', yaxis_title='Focus Score', yaxis_range=[0, 100])\n",
    "  st.plotly_chart(fig_focus)\n",
    "  \n",
    "  # Front Camera Time vs Not Front Camera Time\n",
    "  front_camera_time = df.attrs.get('total_front_minutes', 0)\n",
    "  not_front_camera_time = df.attrs.get('total_not_front_minutes', 0)\n",
    "  fig_camera = go.Figure(data=[go.Bar(x=['Front Camera', 'Not Front Camera'], y=[front_camera_time, not_front_camera_time], marker_color=['#636EFA', '#EF553B'])])\n",
    "  fig_camera.update_layout(title='Front Camera Time vs Not Front Camera Time', xaxis_title='Camera Position', yaxis_title='Time (minutes)')\n",
    "  st.plotly_chart(fig_camera)\n",
    "  \n",
    "  # Eye Direction Distribution\n",
    "  eye_direction_counts = df['eye_direction'].value_counts()\n",
    "  eye_direction_counts = eye_direction_counts[eye_direction_counts.index != 'Unknown']\n",
    "  fig_eye = go.Figure(data=[go.Pie(labels=eye_direction_counts.index, values=eye_direction_counts.values)])\n",
    "  fig_eye.update_layout(title='Eye Direction Distribution')\n",
    "  st.plotly_chart(fig_eye)\n",
    "  \n",
    "  # Sleep Analysis\n",
    "  st.subheader(\"Sleep Analysis\")\n",
    "  sleep_count = df['sleep_count'].iloc[-1]\n",
    "  if sleep_count > 0:\n",
    "      st.write(f\"Number of 10-second continuous sleep intervals: {sleep_count}\")\n",
    "  else:\n",
    "      st.write(\"Great job staying attentive throughout the session!\")\n",
    "  \n",
    "  # Session Statistics\n",
    "  st.subheader(\"Session Statistics\")\n",
    "  avg_focus_score = df['focus_score'].mean()\n",
    "  st.write(f\"Average Focus Score: {avg_focus_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pdf(df):\n",
    "  buffer = BytesIO()\n",
    "  sns.set_style(\"whitegrid\")  # Set seaborn style to include grids\n",
    "  with PdfPages(buffer) as pdf:\n",
    "      # Focus Score Over Time\n",
    "      plt.figure(figsize=(10, 6))\n",
    "      sns.lineplot(x='timestamp_min', y='focus_score', data=df)\n",
    "      plt.title('Focus Score Over Time')\n",
    "      plt.xlabel('Time (minutes)')\n",
    "      plt.ylabel('Focus Score')\n",
    "      plt.ylim(0, 100)\n",
    "      pdf.savefig()\n",
    "      plt.close()\n",
    "\n",
    "      # Front Camera Time vs Not Front Camera Time\n",
    "      front_camera_time = df.attrs.get('total_front_minutes', 0)\n",
    "      not_front_camera_time = df.attrs.get('total_not_front_minutes', 0)\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      sns.barplot(x=['Front Camera', 'Not Front Camera'], y=[front_camera_time, not_front_camera_time], palette=['#636EFA', '#EF553B'])\n",
    "      plt.title('Front Camera Time vs Not Front Camera Time')\n",
    "      plt.ylabel('Time (minutes)')\n",
    "      pdf.savefig()\n",
    "      plt.close()\n",
    "\n",
    "      # Eye Direction Distribution\n",
    "      eye_direction_counts = df['eye_direction'].value_counts()\n",
    "      eye_direction_counts = eye_direction_counts[eye_direction_counts.index != 'Unknown']\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      sns.barplot(x=eye_direction_counts.index, y=eye_direction_counts.values, palette='viridis')\n",
    "      plt.title('Eye Direction Distribution')\n",
    "      plt.ylabel('Count')\n",
    "      plt.xlabel('Eye Direction')\n",
    "      pdf.savefig()\n",
    "      plt.close()\n",
    "\n",
    "      # Blink Analysis (Added to PDF)\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      total_blinks = df['total_blinks'].iloc[-1]\n",
    "      total_duration = df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]\n",
    "      total_minutes = total_duration / 60\n",
    "      blinks_per_minute = total_blinks / total_minutes if total_minutes > 0 else 0\n",
    "      sns.barplot(x=['Blinks per Minute'], y=[blinks_per_minute], palette='magma')\n",
    "      plt.title('Blink Analysis')\n",
    "      plt.ylabel('Blinks per Minute')\n",
    "      pdf.savefig()\n",
    "      plt.close()\n",
    "\n",
    "  buffer.seek(0)\n",
    "  return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app():\n",
    "  st.title(\"📊 Focus Detection with WebRTC and Video Analysis\")\n",
    "\n",
    "  # Sidebar for configuration\n",
    "  st.sidebar.header(\"🔧 Configuration\")\n",
    "  global CENTER_THRESHOLD, SIDE_THRESHOLD, BLINK_THRESHOLD, DISCOUNT_SIDE, DISCOUNT_EYES\n",
    "\n",
    "  # CENTER_THRESHOLD = st.sidebar.slider(\"Center Look Threshold (seconds)\", 1, 10, 5, key=\"center_threshold\")\n",
    "  SIDE_THRESHOLD = st.sidebar.slider(\"Side Look Threshold (seconds)\", 1, 10, 5, key=\"side_threshold\")\n",
    "  DISCOUNT_SIDE = st.sidebar.slider(\"Side Look Discount (%)\", 1, 5, 1, key=\"discount_side\")\n",
    "  BLINK_THRESHOLD = st.sidebar.slider(\"Blink Threshold (seconds)\", 1, 10, 5, key=\"blink_threshold\")\n",
    "  DISCOUNT_EYES = st.sidebar.slider(\"Closed Eyes Discount (%)\", 5, 30, 5, key=\"discount_eyes\")\n",
    "  \n",
    "  # Tabs for Live Video and Upload Video\n",
    "  tab1, tab2 = st.tabs([\"🎥 Live Video\", \"📤 Upload Video\"])\n",
    "  \n",
    "  with tab1:\n",
    "      st.header(\"🔴 Webcam Feed\")\n",
    "      webrtc_streamer(\n",
    "          key=\"camera\",\n",
    "          mode=WebRtcMode.SENDRECV,\n",
    "          media_stream_constraints={\n",
    "              \"video\": True,\n",
    "              \"audio\": False,\n",
    "          },\n",
    "          video_frame_callback=video_frame_callback,\n",
    "      )\n",
    "  \n",
    "  with tab2:\n",
    "      st.header(\"📥 Upload Video for Analysis\")\n",
    "      uploaded_file = st.file_uploader(\"Choose a video file\", type=[\"mp4\", \"avi\", \"mov\"])\n",
    "      \n",
    "      if uploaded_file is not None:\n",
    "          st.video(uploaded_file)\n",
    "          \n",
    "          if st.button(\"🔍 Analyze Video\"):\n",
    "              with st.spinner(\"Analyzing video...\"):\n",
    "                  results_df = process_uploaded_video(uploaded_file)\n",
    "              \n",
    "              st.success(\"✅ Analysis complete!\")\n",
    "              create_dashboard(results_df)\n",
    "              \n",
    "              # Export to PDF\n",
    "              pdf_file = export_to_pdf(results_df)\n",
    "              st.download_button(\n",
    "                  label=\"💾 Download PDF Report\",\n",
    "                  data=pdf_file,\n",
    "                  file_name=\"focus_analysis_report.pdf\",\n",
    "                  mime=\"application/pdf\"\n",
    "              )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  app()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
